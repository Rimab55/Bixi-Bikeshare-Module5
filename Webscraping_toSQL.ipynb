{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing relevant libraries for data imports and webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "#Libraries for dateime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "#Libraries for webscraping\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIXI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'BixiRentals2018'  # instert folder name containing all bixi transactions for the year\n",
    "\n",
    "def get_bixi_data(folder):\n",
    "    \"\"\"\n",
    "    Returns dataframe combining all .csv files contained in supplied folder name into one dataframe\n",
    "    sorted by date of transaction\n",
    "    \"\"\"\n",
    "    \n",
    "    files = []\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith('.csv'):\n",
    "            files.append(pd.read_csv(f'{folder}/{file}'))\n",
    "\n",
    "    df = pd.concat(files, axis=0, ignore_index=True)\n",
    "    df = df.sort_values(by='start_date')\n",
    "    \n",
    "    # assign name to df to later save into a SQL table\n",
    "    df.name = 'bixi'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "bixi = get_bixi_data(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 : Weather data from wunderground.com - April-November 2018 inclusive as BIXI is available only part of the year in Montreal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.wunderground.com/history/daily/ca/montreal/CYUL/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = '45.445'\n",
    "long = '-73.751'\n",
    "key = '6532d6454b8aa370768e63d6ba5a832e'\n",
    "\n",
    "def get_weather_month(lat,long,key,start,end):\n",
    "    \"\"\"\n",
    "    Returns dataframe with weather scraped from api/weather.com for the latitude & longitude mentioned\n",
    "    and start to end date. There is a maximum of 31 days per request\n",
    "    \"\"\"\n",
    "    \n",
    "    url = f'https://api.weather.com/v1/geocode/{lat}/{long}/observations/historical.json?apiKey={key}&startDate={start}&endDate={end}&units=e'\n",
    "    results = requests.get(url).json()['observations']\n",
    "    df = pd.DataFrame([result for result in results])\n",
    "    \n",
    "    # Columns to keep\n",
    "    keep_columns = ['valid_time_gmt','day_ind','feels_like','heat_index','precip_hrly',\n",
    "                    'rh','temp','uv_desc','uv_index','wc','wspd','wx_phrase']\n",
    "    \n",
    "    # Creates df with columns to keep\n",
    "    df = df[keep_columns]\n",
    "    \n",
    "    # Converting Greenwich meantime timestamp into date time\n",
    "    df['valid_time_gmt'] = df['valid_time_gmt'].apply(lambda x: datetime.fromtimestamp(x).strftime('%Y-%m-%d %H:%M'))\n",
    "    df['valid_time_gmt'] = pd.to_datetime(df['valid_time_gmt'])\n",
    "    \n",
    "    # Extract date & time from timestamp\n",
    "    df['date'] = df['valid_time_gmt'].apply(lambda x: datetime.date(x))\n",
    "    df['time'] = df['valid_time_gmt'].apply(lambda x: datetime.time(x))\n",
    "    df.drop(['valid_time_gmt'], axis = 1, inplace = True)\n",
    "    \n",
    "    # Renaming for better understanding\n",
    "    # rh stands for relative humidity and wx_phrase stands for weather condition\n",
    "    df.rename(columns={'rh':'humidity','wx_phrase':'condition','wspd':'wind_speed'}, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_weather(lat, long, key, year):\n",
    "    \"\"\"\n",
    "    Returns dataframe combining weather information for supplied latitude and longitude for the months\n",
    "    of April-November inclusive for the specified year\n",
    "    \"\"\"\n",
    "    \n",
    "    #Calling get_weather function for needed months\n",
    "    apr = get_weather(lat,long,key,f'{year}0401',f'{year}0430')\n",
    "    may = get_weather(lat,long,key,f'{year}0501',f'{year}0531')\n",
    "    jun = get_weather(lat,long,key,f'{year}0601',f'{year}0630')\n",
    "    jul = get_weather(lat,long,key,f'{year}0701',f'{year}0731')\n",
    "    aug = get_weather(lat,long,key,f'{year}0801',f'{year}0831')\n",
    "    sep = get_weather(lat,long,key,f'{year}0901',f'{year}0930')\n",
    "    octo = get_weather(lat,long,key,f'{year}1001',f'{year}1030')\n",
    "    nov = get_weather(lat,long,key,f'{year}1101',f'{year}1130')\n",
    "    \n",
    "    #Bixi is available for April to November inclusive\n",
    "    months = [apr,may,jun,jul,aug,sep,octo,nov]\n",
    "    \n",
    "    df = pd.concat(months, axis=0, ignore_index=True)\n",
    "    \n",
    "    # assign name to df to later save into a SQL table\n",
    "    df.name = 'weather'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = get_all_weather(lat,long,key,year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Scraping public holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.officeholidays.com/countries/canada/quebec/2018.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018\n",
    "\n",
    "def get_holidays(year):\n",
    "    \"\"\"Returns dataframe with scraped holidays for the province of Quebec for the supplied year\"\"\"\n",
    "\n",
    "    url = f'https://www.officeholidays.com/countries/canada/quebec/{year}.php'\n",
    "    html = requests.get(url)\n",
    "    \n",
    "    # Pass the page contents to beautiful soup for parsing\n",
    "    soup = BeautifulSoup(html.content, 'html.parser') \n",
    "        \n",
    "    # Get holiday dates\n",
    "    holidays = [\"\".join(i.contents) for i in soup.find_all('time')]\n",
    "    \n",
    "    # Get holiday description\n",
    "    holiday_desc = [i.contents for i in soup.find_all('a')][-22:-11]\n",
    "    holiday_desc = [val.strip('  ') for holiday in holiday_desc for val in holiday]\n",
    "    \n",
    "    # Create dataframe with Holiday & Description\n",
    "    df = pd.DataFrame(list(zip(holidays, desc_holidays)), columns= ['holidays','holiday_desc'])\n",
    "    \n",
    "    # assign name to df to later save into a SQL table\n",
    "    df.name = 'holiday'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = get_holidays(2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving results to SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [bixi, weather, holidays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_sql(dfs, db_name):\n",
    "    \"\"\"\n",
    "    Creates a SQL database with the specified name and saves dataframes\n",
    "    listed in dfs database\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create database\n",
    "\n",
    "    connex = sqlite3.connect(f'{db_name}.db')  \n",
    "    cur = connex.cursor()\n",
    "\n",
    "    # Create SQL tables in database\n",
    "    for df in dfs:\n",
    "        df.to_sql(name = df.name, con=connex, if_exists=\"replace\", index=False)  \n",
    "    \n",
    "    # Close \n",
    "    connex.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_sql(dfs, 'bixi_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
